{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e071b84",
   "metadata": {},
   "source": [
    "# Welcome to the `tell` Quickstarter! \n",
    "\n",
    "### **`tell` is an open-source Python package for projecting future electricty demand in the United States.**\n",
    "\n",
    "## A little about `tell`\n",
    "\n",
    "The Total ELectricity Load (TELL) model projects the short- and long-term evoluation of hourly electricity demand (load) in response to future changes in weather and climate. The purpose of `tell` is to generate end-of-century hourly profiles of electricity demand across the entire Conterminous United States (CONUS) at a spatial resolution adequate for input to a unit commitment/economic dispatch (UC/ED) model while also maintaining consistency with the long-term growth and evolution of annual state-level electricity demand projected by an economically driven human-Earth system model. `tell` takes as input future projections of the hourly time-series of meteorology and decadal populations and uses the temporal variations in weather to project hourly profiles of total electricity demand. The core predictions in `tell` are based on a series of multilayer perceptron (MLP) models for individual Balancing Authorities (BAs). Those MLP models are trained on historical observations of weather and electricity demand. Hourly projections from `tell` are scaled to match the annual state-level total electricity loads projected by the U.S. version of the Global Change Analysis Model (GCAM-USA). GCAM-USA captures the long-term co-evolution of the human-Earth system. Using this unique approach allows `tell` to reflect both changes in the shape of the load profile due to variations in weather and the long-term evolution of energy demand due to changes in population, technology, and economics. `tell` is unique from other load forecasting models in that it features an explicit spatial component that allows us to relate projected loads to where they would occur spatially within a grid operations model. The output of `tell` is a series of hourly projections for future electricity demand at the county, state, and BA scale that are quantitatively and conceptually consistent with one another. More information about how the model works and how it can be applied are available on the [Read the Docs](https://immm-sfa.github.io/tell/index.html) site for `tell`.\n",
    "\n",
    "## Lets get started! \n",
    "\n",
    "In this quickstarter we will walk through a series of steps for exploring `tell`, starting with importing the package and ending with visualizing the output. This quickstarter is based on a subset of example forcing data for `tell`. This allows the user to walk through the entire `tell` package in a matter of minutes. For the visualizations throughout this notebook, the user can choose whether or not to save these plots by setting the \"save_images\" and \"image_resolution\" flags in each function.\n",
    "\n",
    "## 1. Install `tell`\n",
    "\n",
    "`tell` is available via GitHub repository by using the pip install functionality below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1c3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package using pip:\n",
    "# pip install tell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86db683a-70a2-4f89-a1d6-4c6d5f180272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the TELL package and information about your operating system:\n",
    "import os \n",
    "import tell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fce96-4576-4a2d-9db6-4d0be72b3c1d",
   "metadata": {},
   "source": [
    "## 2. Install the package of raw data underpinning `tell`\n",
    "\n",
    "`tell` is based on open-source publicly accessible data. For convienence, we've packaged all of the core data underpinning `tell` into a [Zenodo data package](https://zenodo.org/record/5714756#.YhkTjxPMJTY). In order to run this notebook, first set the local directory where you would like to store the package data and the run the \"install_tell_raw_data\" function below. Note that the raw data package will require ~1.6 GB of storage and can take several minutes to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7cc0f66-ba83-47d4-b161-0b1ad076064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the current working directory, the subdirectory where the data will be stored, and the image output subdirectory:\n",
    "current_dir =  os.path.join(os.path.dirname(os.getcwd()))\n",
    "tell_data_dir = os.path.join(current_dir, r'tell_data')\n",
    "tell_image_dir = os.path.join(tell_data_dir, r'outputs', r'visualizations')\n",
    "\n",
    "# If the \"tell_data_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(tell_data_dir):\n",
    "   os.makedirs(tell_data_dir)\n",
    "\n",
    "# If the \"tell_image_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(tell_image_dir):\n",
    "   os.makedirs(tell_image_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a037554",
   "metadata": {},
   "source": [
    "## 3. MLP model training and projection\n",
    "\n",
    "This section of the notebook takes the data processed and compiled above and trains a multilayer perceptron (MLP) model for each of the 54 BAs in `tell`. The MLP models use temporal variations in weather to project hourly demand. More information about this approach is in the MLP section of the `tell` [User Guide](https://immm-sfa.github.io/tell/user_guide.html). We include pre-trained models within the `tell` repository. If you want to explore the model training aspect you can use the code in Section 3.1 to retrain the MLP models for a single BA or a batch of BAs. Note that since the `save_model` parameter is set to \"False\" by default running these training steps will not overwrite the models included in `tell`. If you want to skip this step you can move to Section 3.2 to see how `tell` projects future loads by BA using weather projections.\n",
    "\n",
    "### 3.1. MLP training\n",
    "The first step is to train the MLP and linear models using the historical weather and load datasets created in Section 3. The default settings for the MLP model training steps are included in the `mlp_settings.yml` file included in the data folder of the `tell` repository. By default the MLP models are trained on data from 2016-2018 and evaluated using data from 2019. The time windows for training and evaluating the models can be modified by altering the `start_time`, `end_time`, and `split_datetime` parameters when calling the `tell.train` function. The first code block shows how to train the MLP and linear models for a single BA. We also include a function to do some basic analysis of the trained model's performance. More extensive evaluation of the `tell` predictive models is included in the `tell_mlp_calibration_evaluation.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b742f-c5e9-487b-be65-ee3f25199ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more information about the training of predictive models you can call the help function:\n",
    "help(tell.predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccddc4b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2x/xdz7fwts5fj0gdl0b7lbtc_cbqnqwx/T/ipykernel_10104/2823739889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the MLP training step for a single BA (i.e., \"region\"):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m prediction_df, validation_df = tell.train(region = 'PJM',\n\u001b[0m\u001b[1;32m      3\u001b[0m                                           data_dir = os.path.join(tell_data_dir, r'outputs', r'compiled_historical_data'))\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# View the head of the prediction dataframe that contains the time-series of projected load in the evaluation year:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_repos/tell/tell/tell/mlp_train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(region, data_dir, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# run the MLP model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     y_predicted_normalized = train_mlp_model(region=region,\n\u001b[0m\u001b[1;32m    190\u001b[0m                                              \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                                              \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_repos/tell/tell/tell/mlp_train.py\u001b[0m in \u001b[0;36mtrain_mlp_model\u001b[0;34m(region, x_train, y_train, x_test, mlp_hidden_layer_sizes, mlp_max_iter, mlp_validation_fraction, save_model, model_output_directory)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# fit the model to data matrix X (training features) and target Y (training targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# predict using the multi-layer perceptron model using the test features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \"\"\"\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfirst_pass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;31m# First time training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Initialize lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, y, layer_units, dtype)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             coef_init, intercept_init = self._init_coef(\n\u001b[0m\u001b[1;32m    345\u001b[0m                 \u001b[0mlayer_units\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_units\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             )\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_init_coef\u001b[0;34m(self, fan_in, fan_out, dtype)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;31m# Generate weights and bias:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         coef_init = self._random_state.uniform(\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0;34m-\u001b[0m\u001b[0minit_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         )\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.uniform\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.cont\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# Run the MLP training step for a single BA (i.e., \"region\"):\n",
    "prediction_df, validation_df = tell.train(region = 'PJM',\n",
    "                                          data_dir = os.path.join(tell_data_dir, r'outputs', r'compiled_historical_data'))\n",
    "\n",
    "# View the head of the prediction dataframe that contains the time-series of projected load in the evaluation year:\n",
    "display(prediction_df.head(10))\n",
    "\n",
    "# View validation dataframe that contains error statistics for the trained model:\n",
    "validation_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae10c90-eaa8-46d3-8df1-c5d3c799b67b",
   "metadata": {},
   "source": [
    "You can also train multiple BAs at the same time using parallel processing. The example code block below retrains the models for all BAs in `tell`. This takes ~1 minute on a standard personal computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87a1a00-7b3b-4e66-8eec-8828d91b6a53",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/burl878/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/Users/burl878/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/burl878/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/burl878/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/burl878/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/burl878/Documents/code_repos/tell/tell/tell/mlp_train.py\", line 189, in train\n    y_predicted_normalized = train_mlp_model(region=region,\n  File \"/Users/burl878/Documents/code_repos/tell/tell/tell/mlp_train.py\", line 65, in train_mlp_model\n    mlp.fit(x_train, y_train)\n  File \"/Users/burl878/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 752, in fit\n    return self._fit(X, y, incremental=False)\n  File \"/Users/burl878/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 410, in _fit\n    self._initialize(y, layer_units, X.dtype)\n  File \"/Users/burl878/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 344, in _initialize\n    coef_init, intercept_init = self._init_coef(\n  File \"/Users/burl878/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 368, in _init_coef\n    coef_init = self._random_state.uniform(\n  File \"mtrand.pyx\", line 1118, in numpy.random.mtrand.RandomState.uniform\n  File \"_common.pyx\", line 598, in numpy.random._common.cont\nTypeError: 'numpy.float64' object cannot be interpreted as an integer\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2x/xdz7fwts5fj0gdl0b7lbtc_cbqnqwx/T/ipykernel_63460/481406758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run the MLP training step for the list of BAs using parallel processing streams:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m prediction_df, validation_df = tell.train_batch(target_region_list = ba_abbrev_list,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                                 \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtell_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'outputs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'compiled_historical_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                 \u001b[0mmlp_linear_adjustment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code_repos/tell/tell/tell/mlp_train.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(target_region_list, data_dir, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;31m# run all regions in target list in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     results = Parallel(n_jobs=n_jobs, backend=\"loky\")(delayed(train)(region=region,\n\u001b[0m\u001b[1;32m    306\u001b[0m                                                                      \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                                                                      **kwargs) for region in target_region_list)\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_tell/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# Generate a list of BA abbreviations to process:\n",
    "ba_abbrev_list = tell.get_balancing_authority_to_model_dict().keys()\n",
    "\n",
    "# Run the MLP training step for the list of BAs using parallel processing streams:\n",
    "prediction_df, validation_df = tell.train_batch(target_region_list = ba_abbrev_list,\n",
    "                                                data_dir = os.path.join(tell_data_dir, r'outputs', r'compiled_historical_data'),\n",
    "                                                save_model = False,\n",
    "                                                n_jobs = -1)\n",
    "\n",
    "# View the validation dataframe that contains error statistics for the trained models:\n",
    "validation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51783f4d-324e-47eb-ac3d-9b013f9682e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the statistical performance (e.g., RMS_ABS, RMS_NORM, MAPE, or R2) of the predictive models across all the BAs in TELL:\n",
    "tell.plot_mlp_summary_statistics(validation_df, \n",
    "                                 image_output_dir = tell_image_dir,\n",
    "                                 image_resolution = 150,\n",
    "                                 save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000fde97-8006-47ed-bec2-2c3fec6a70f1",
   "metadata": {},
   "source": [
    "### 4.2. MLP model projection\n",
    "Next we use the trained MLP models to project future loads in each BA using the sample climate forcing downloaded in Section 3.4. The outcomes of this projection step are then used in the forward execution of `tell` in Section 5. The sample forcing data includes four years of future meteorology for each BA: 2039, 2059, 2079, and 2099. Those are the only valid options for the `year` variable when calling the prediciton functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4161e-0533-40de-88bd-b5b81ec9de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the MLP prediction step for a single BA (i.e., \"region\"):\n",
    "pdf = tell.predict(region = 'PJM',\n",
    "                   year = 2039,\n",
    "                   data_dir = os.path.join(tell_data_dir, r'sample_forcing_data', r'future_weather', r'rcp85hotter_ssp5'),\n",
    "                   datetime_field_name = 'Time_UTC',\n",
    "                   save_prediction = True,\n",
    "                   prediction_output_directory = os.path.join(tell_data_dir, r'outputs', r'mlp_output', r'rcp85hotter_ssp5'))\n",
    "\n",
    "# View the prediction dataframe:\n",
    "pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6b851-29c9-4a1b-a149-ee341f1af5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of BA abbreviations to process:\n",
    "ba_abbrev_list = tell.get_balancing_authority_to_model_dict().keys()\n",
    "\n",
    "# Run the MLP prediction step for the list of BAs using parallel processing streams:\n",
    "pdf = tell.predict_batch(target_region_list = ba_abbrev_list,\n",
    "                         year = 2079,\n",
    "                         data_dir = os.path.join(tell_data_dir, r'sample_forcing_data', r'future_weather', r'rcp85hotter_ssp5'),\n",
    "                         datetime_field_name = 'Time_UTC',\n",
    "                         mlp_linear_adjustment = True,\n",
    "                         save_prediction = True,\n",
    "                         prediction_output_directory = os.path.join(tell_data_dir, r'outputs', r'mlp_output', r'rcp85hotter_ssp5'),\n",
    "                         n_jobs = -1)\n",
    "\n",
    "# View the prediction dataframe:\n",
    "pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9048639",
   "metadata": {},
   "source": [
    "## 5. Model forward execution\n",
    "\n",
    "This section of the `tell` workflow takes the .csv files produced by the `tell` MLP models and distributes the projected load to the counties that each BA operates in. The county-level hourly loads are then summed to the state-level and scaled to match the state-level annual loads produced by GCAM-USA. Four sets of output files are generated: county-level hourly loads, state-level hourly loads, hourly loads for each BA, and a summary file that includes state-level annual loads from TELL and GCAM-USA as well as the scaling factors. Note that since it takes a while to write out the county-level output data this output is optional. To output county-level load projections just set the \"save_county_data\" flag to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad62d3-b548-4e8a-9ab1-4c0aaa28f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model, linear_model, normalized_dict = tell.load_predictive_models(region='NYIS',\n",
    "                                                                       model_output_directory='/Users/burl878/Documents/tell/tell/tell/data/models/',\n",
    "                                                                       mlp_linear_adjustment=True)\n",
    "\n",
    "normalized_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the TELL model forward in time for a given year:\n",
    "summary_df, ba_time_series_df, state_time_series_df = tell.execute_forward(year_to_process = '2079',\n",
    "                                                                           scenario_to_process = 'rcp85hotter_ssp5',\n",
    "                                                                           data_input_dir = tell_data_dir,\n",
    "                                                                           save_county_data = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae90672",
   "metadata": {},
   "source": [
    "## 6. Model visualization\n",
    "\n",
    "The final section of this quickstarter notebook plots some of the output of `tell` to give the user a flavor of what the model is doing. Because `tell` can take a few minutes to run we have pre-ran the model for the sample weather years described above. The first step in this section downloads that sample `tell` output data package from the [Zenodo data package](https://zenodo.org/record/6338472#.YieU0BPMJTY) and then visualizes the output in multiple ways. Note that the sample output data covers the years 2039, 2059, 2079, and 2099 so those are the only valid values for the \"year_to_plot\" variable in each function call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc207feb",
   "metadata": {},
   "source": [
    "### 6.1. Plot a map of the state scaling factors\n",
    "\n",
    "The first visualization plots the state level scaling factors that force the annual total loads projected by `tell` at the state-level to agree with those from GCAM-USA. Values closer to\n",
    "1 indicate that the models are in closer agreement. In this case using the sample output (which relies on a generic GCAM-USA simulation) you shouldn't read too much into disagreements between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the state-level scaling factors:\n",
    "tell.plot_state_scaling_factors(year_to_plot = '2099', \n",
    "                                scenario_to_plot = 'rcp85hotter_ssp5',  \n",
    "                                data_input_dir = tell_data_dir, \n",
    "                                image_output_dir = tell_image_dir,\n",
    "                                image_resolution = 150,\n",
    "                                save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e293f",
   "metadata": {},
   "source": [
    "### 6.2. Plot the state annual total loads from GCAM-USA and `tell`\n",
    "\n",
    "Next we plot the annual total loads from both GCAM-USA and `tell`. The data plotted here are in units of TWh and the `tell` values are the unscaled projections. The scaled projections `tell` are by definition equal to those from GCAM-USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the annual total loads from both GCAM-USA and TELL:\n",
    "tell.plot_state_annual_total_loads(year_to_plot = '2079',\n",
    "                                   scenario_to_plot = 'rcp85hotter_ssp5',  \n",
    "                                   data_input_dir = tell_data_dir,\n",
    "                                   image_output_dir = tell_image_dir,\n",
    "                                   image_resolution = 150,\n",
    "                                   save_images = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c21d43",
   "metadata": {},
   "source": [
    "### 6.3. Plot the time-series of total hourly loads for a given state\n",
    "\n",
    "Here we plot time-series of the raw (unscaled) and scaled total loads from `tell` at the state level. The user specifies which state they want to plot using the \"state_to_plot\" variable in the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time-series of raw and scaled loads from TELL at the state level for a user-specified state:\n",
    "tell.plot_state_load_time_series(state_to_plot = 'Connecticut', \n",
    "                                 year_to_plot = '2039',\n",
    "                                 scenario_to_plot = 'rcp85hotter_ssp5', \n",
    "                                 data_input_dir = tell_data_dir,\n",
    "                                 image_output_dir = tell_image_dir,\n",
    "                                 image_resolution = 150,\n",
    "                                 save_images = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18520f3",
   "metadata": {},
   "source": [
    "### 6.4. Plot the load duration curve for a given state\n",
    "\n",
    "Our last plot at the state level is the load duration curve which shows the frequency at which a given load occurs in a state. The user specifies which state they want to plot using the \"state_to_plot\" variable in the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the load duration curve at the state level for a user-specified state:\n",
    "tell.plot_state_load_duration_curve(state_to_plot = 'North Carolina', \n",
    "                                    year_to_plot = '2039',\n",
    "                                    scenario_to_plot = 'rcp85hotter_ssp5', \n",
    "                                    data_input_dir = tell_data_dir,\n",
    "                                    image_output_dir = tell_image_dir,\n",
    "                                    image_resolution = 150,\n",
    "                                    save_images = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc2702",
   "metadata": {},
   "source": [
    "### 6.5. Plot the time-series of total hourly loads for a given BA\n",
    "\n",
    "Our final visualization plots the time-series of the raw (unscaled) and scaled total loads from `tell` at the BA level. The user specifies which BA they want to plot using the \"ba_to_plot\" variable in the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5c303-a15e-4c9c-b97a-462f30618328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time-series of raw and scaled loads from TELL at the BA level for a user-specified BA (e.g., PJM, CISO, ERCO, etc.):\n",
    "tell.plot_ba_load_time_series(ba_to_plot = 'NYIS', \n",
    "                              year_to_plot = '2099',\n",
    "                              scenario_to_plot = 'rcp85hotter_ssp5', \n",
    "                              data_input_dir = tell_data_dir,\n",
    "                              image_output_dir = tell_image_dir,\n",
    "                              image_resolution = 150,\n",
    "                              save_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5832f3-be0f-4d82-acaa-8301bc34aefe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.4_tell",
   "language": "python",
   "name": "py3.9.4_tell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
