{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347dacd7-25c2-4a0a-95a6-187f7823c415",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Welcome to the TELL Quickstarter! \n",
    "\n",
    "### **`tell` is an open-source Python package for predicting future electricty load in the Lower 48 United States.**\n",
    "\n",
    "## A little about `tell`\n",
    "\n",
    "The Total ELectricity Load (TELL) model provides a framework that integrates aspects of both short- and long-term predictions of electricity demand in a coherent and scalable way. tell takes as input gridded hourly time-series of meteorology and uses the temporal variations in weather to predict hourly profiles of total electricity demand for every county in the l ower 48 United States using a multilayer perceptron (MLP) approach. Hourly predictions from tell are then scaled to match the annual state-level total electricity loads predicted by the U.S. version of the Global Change Analysis Model (GCAM-USA). GCAM-USA is designed to capture the long-term co-evolution of the human-Earth system. Using this unique approach allows tell to reflect both changes in the shape of the load profile due to variations in weather and climate and the long-term evolution of energy demand due to changes in population, technology, and economics. tell is unique from other probabilistic load forecasting models in that it features an explicit spatial component that allows us to relate predicted loads to where they would occur spatially within a grid operations model.\n",
    "\n",
    "## Lets get started! \n",
    "\n",
    "In this quickstarter we will walk through a subset of the data used in `tell`, starting with importing the package and ending with data visualization. This allows the user to walk through the entire `tell` package in a matter of minutes. If you have more questions please feel free to visit the [Read the Docs](https://immm-sfa.github.io/tell/index.html) site for `tell`.\n",
    "\n",
    "### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e9c75a-eb13-4868-9c2d-de6a85920592",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tell'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5896/3595253283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mim3components\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tell'"
     ]
    }
   ],
   "source": [
    "import tell\n",
    "import im3components "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fce96-4576-4a2d-9db6-4d0be72b3c1d",
   "metadata": {},
   "source": [
    "### Install package data\n",
    "\n",
    "**NOTE: The package data will require approximately 1.4 GB of storage.**\n",
    "\n",
    "Set the local directory where you would like to store the package data and run the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8840888f-e1b9-43c6-9b86-d4682edb2c7a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tell' has no attribute 'install_package_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19420/1485562569.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstall_package_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tell' has no attribute 'install_package_data'"
     ]
    }
   ],
   "source": [
    "# Change to your local directory where you would like to store the data\n",
    "data_dir = 'C:/Users/mcgr323/projects/tell_valid/tell/tell_raw_data'\n",
    "\n",
    "# Download the raw data from the Zenodo package\n",
    "tell.install_package_data(data_dir = data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b10c8-5872-42a9-84ae-ba09ef4a90c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Data processing for TELL\n",
    "\n",
    "In the next few code blocks we will load and manipulate the nescessary data for the `tell`  package. This consists of hourly load, population and meterology for the CONUS, which will be loaded in from raw data sources, manipulated and then compiled together to use as input for the MLP model. Please follow the steps below to produce the hourly input data, if you have already finished this step you can proceed to **2. Model training and prediction**\n",
    "    \n",
    "### 1.1 Hourly load\n",
    "\n",
    "Here we load in the raw EIA 930 hourly load profiles for all Balancing Authorities (BAs), subset for the wanted columns only and then output the hourly load as csvs to be compiled later with population, and meteorlogy to be fed to the MLP model downstream for predict future load. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f884bf82-b057-4492-a81b-3ded0888fd25",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Hourly load data (EIA 930):\n",
    "\n",
    "# Set the data input and output directories:\n",
    "EIA_930_input_dir = 'C:/Users/mcgr323/projects/tell_valid/tell/tell_raw_data'\n",
    "EIA_930_output_dir = 'C:/Users/mcgr323/projects/tell/ba_hourly_inputs/ba_Hourly_Load'\n",
    "\n",
    "# Process the hourly load data\n",
    "tell.process_eia_930(EIA_930_input_dir, EIA_930_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274fd1f-de15-4987-b9fe-c30b2af57c4e",
   "metadata": {},
   "source": [
    "### 1.2 Population data\n",
    "\n",
    "For this data processing step we will load in the annual population by FIPS code, merge by FIPS code to get the correspondng BA number, sum by  year and BA number and then interpolate the annual population to hourly population in order to feed it to the MLP model downstream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bb4ead-6a55-4b42-bc0a-80e849aef2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# County population data:\n",
    "\n",
    "# Set the data input and output directories:\n",
    "population_input_dir = 'C:/Users/mcgr323/projects/tell_valid/tell/tell_raw_data'\n",
    "mapping_input_dir = 'C:/Users/mcgr323/projects/tell_valid/tell/tell_raw_data'\n",
    "pop_output_dir = 'C:/Users/mcgr323/projects/tell/ba_hourly_inputs/ba_population'\n",
    "output_dir = 'C:/Users/mcgr323/projects/tell/ba_hourly_inputs/bb_population'\n",
    "\n",
    "# Set some processing flags:\n",
    "start_year = 2015;  # Starting year of time series\n",
    "end_year = 2019;  # Ending year of time series\n",
    "\n",
    "ba_pop_interpolate(mapping_input_dir, population_input_dir, output_dir, start_year, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a3913-25ec-4d9f-8544-ecff68e4d467",
   "metadata": {},
   "source": [
    "### 1.3 Meterology data\n",
    "\n",
    "Here we use the `im3components` package to load in the WRF meterology data, average WRF meteorology by county and then aggregate them into annual hourly time-series of population-weighted meteorology for each balancing authority (BA). All times are in UTC. Missing values are reported as -9999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9245d-c18b-4a13-8f1d-1933b22fcac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRF_input_dir = 'C:/Users/mcgr323/projects/tell_valid/tell/tell_raw_data'\n",
    "WRF_output_dir = 'C:/Users/mcgr323/projects/tell/ba_hourly_inputs/ba_wrf'\n",
    "\n",
    "from im3components.wrf_tell.wrf_tell_counties import wrf_to_tell_counties\n",
    "from im3components.wrf_tell.wrf_tell_balancing_authorities import wrf_to_tell_balancing_authorities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f5df8-16d9-400c-acdf-2f0d34b971f2",
   "metadata": {},
   "source": [
    "### 1.4 Compile hourly load, population and meterology data\n",
    "\n",
    "Here we compile all the data processing steps above for hourly load (EIA 930), population (county FIPS) and meteorlogy (WRF) to get a final cleaned up dataset to use as an input to the MLP model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef7700-4eee-4d02-a8f9-a2ecca806943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile hourly load, hourly population and hourly WRF data for MLP model\n",
    "EIA_930_output_dir = 'C:/Users/mcgr323/projects/tell/ba_hourly_inputs/ba_hourly_load'\n",
    "pop_output_dir = 'C:/Users/mcgr323/projects/tell/ba_hourly_inputs/ba_population'\n",
    "WRF_output_dir = 'C:/Users/mcgr323/projects/tell/ba_hourly_inputs/ba_wrf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de8b82-5cdb-4b74-97b0-3af228c0e002",
   "metadata": {},
   "source": [
    "## 2. Model training and prediction\n",
    "\n",
    "This step takes the data processed and compiled above and runs a multilayer perceptron (MLP) model to predict future hourly load. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12b03b-901d-4e5c-ac9d-7013fdaf1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "data_dir = 'C:/Users/mcgr323/projects/tell/BA_hourly_inputs/compiled_csv_files'\n",
    "output_dir = 'C:/Users/mcgr323/projects/tell/mlp_model_output'\n",
    "batch_run = True\n",
    "target_ba_list = None\n",
    "generate_plots = True\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "df = tell.predict(data_dir=data_dir,\n",
    "                  out_dir=output_dir,\n",
    "                  batch_run=batch_run,\n",
    "                  target_ba_list=target_ba_list,\n",
    "                  generate_plots=generate_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1986d71-1553-45e4-b33a-2ee1186e4b16",
   "metadata": {},
   "source": [
    "## 3. Model forward execution\n",
    "\n",
    "This script takes the .csv files produced by the TELL MLP model and distributes the predicted load to the counties that each balancing authority (BA) operates in. The county-level hourly loads are then summed to the state-level and scaled to match the state-level annual loads produced by GCAM-USA. Three sets of output files are generated: county-level hourly loads, state-level hourly loads, and hourly loads for each BA. There is one additional summary output file that includes state-level annual loads from TELL and GCAM-USA as well as the scaling factors.\n",
    "\n",
    "Please set the directories below to your local machine preferences and run the tell.execute_forward function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621d761-70fa-466c-b850-157178ae8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year and GCAM-USA scenario to process:\n",
    "year_to_process = '2020'\n",
    "#gcam_usa_scenario = 'scenario_name'\n",
    "\n",
    "# Set the data input and output directories:\n",
    "mlp_input_dir = 'C:/Users/mcgr323/projects/tell/mlp_model_output/' + year_to_process + '/'\n",
    "ba_geolocation_input_dir = 'C:/Users/mcgr323/projects/tell_valid/tell/tell_raw_data'\n",
    "population_input_dir = 'C:/Users/mcgr323/projects/tell_valid/tell/tell_raw_data'\n",
    "gcam_usa_input_dir = 'C:/Users/mcgr323/projects/tell_valid/tell/tell_raw_data' + gcam_usa_scenario + '/'\n",
    "data_output_dir = 'C:/Users/mcgr323/projects/tell/forward_model_output/' + year_to_process + '/'\n",
    "\n",
    "#Run the MLP model forawrd in time and\n",
    "tell.execute_forward(year_to_process, mlp_input_dir, ba_geolocation_input_dir,\n",
    "                     population_input_dir, gcam_usa_input_dir, data_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c256a-dcf9-43ab-8a27-29ebf7424446",
   "metadata": {},
   "source": [
    "## 4. TELL Visualization\n",
    "\n",
    "Here we provide a few examples of data visualization for the outputs of the TELL model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866517ea-84c2-472c-a763-28fafdadf6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
