{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e343b2f-e0fd-42e8-b41a-6094f8fb6c4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing the Raw Data Underpinning `tell`\n",
    "\n",
    "In this notebook we will load and process the necessary data for `tell`. The raw data (i.e., historical loads, population, meteorology, etc.) is in a variety of different formats determined by their originating organization (e.g., the Energy Information Agency). This series of processing steps cleans the raw data and converts it into a set of simplified .csv files which can be combined together and used as input to the MLP model training steps in `tell`. Follow the sequence below to pre-process the `tell` input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c046d-d40b-4e47-826e-dbb2a16c7f6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install the package of data underpinning `tell`\n",
    "\n",
    "`tell` is based on open-source publicly accessible data. For convienence, we've packaged all of the core data underpinning tell into a [Zenodo data package](https://zenodo.org/record/5714756#.YhkTjxPMJTY). In order to run this notebook, first set the local directory where you would like to store the package data and the run the `install_tell_raw_data` function below. Note that the raw data package will require ~1.6 GB of storage and can take several minutes to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b242f29e-982a-4efb-ad1f-172145688b04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start by importing the `tell` package and information about your operating system:\n",
    "import os \n",
    "import tell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f8864-631b-4683-ad39-51639f1d24a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify the current working directory, the subdirectory where the data will be stored, and the image output subdirectory:\n",
    "current_dir =  os.path.join(os.path.dirname(os.getcwd()))\n",
    "tell_data_dir = os.path.join(current_dir, r'tell_data')\n",
    "tell_image_dir = os.path.join(tell_data_dir, r'visualizations')\n",
    "\n",
    "# If the \"tell_data_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(tell_data_dir):\n",
    "   os.makedirs(tell_data_dir)\n",
    "\n",
    "# If the \"tell_image_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(tell_image_dir):\n",
    "   os.makedirs(tell_image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf32dc1-2b57-49c7-9e9a-5913acc8e9e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download the TELL raw data package from Zenodo:\n",
    "tell.install_tell_raw_data(data_dir = tell_data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1bd0b-4d6d-4632-834f-dd353baafa12",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Spatially mapping BAs to counties\n",
    "\n",
    "The code block underpins the spatial component of `tell`. The function `map_ba_service_territory` uses information about Balancing Authorities (BAs) from the [EIA-861](https://www.eia.gov/electricity/data/eia861/) dataset to spatially map BAs to U.S. counties. This allows us to assign loads projected for individual BAs in `tell` to where they would occur with respect to each other spatially. More information about how BAs are mapped is available on the [Read the Docs](https://immm-sfa.github.io/tell/index.html) site for `tell`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648883d8-5613-4565-901e-de1af5a73b7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute the mapping function for all years from 2015 to 2020:\n",
    "tell.map_ba_service_territory(start_year = 2015,\n",
    "                              end_year = 2020,\n",
    "                              data_input_dir = tell_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c9fb4-b3f3-454f-add1-abdab4de9f72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See the output of the mapping step by plotting the service territory for a given BA (e.g., PJM, CISO, ERCO, etc.) in a given year (e.g., 2015-2020):\n",
    "tell.plot_ba_service_territory(ba_to_plot = 'PACE',\n",
    "                               year_to_plot = '2019',\n",
    "                               data_input_dir = tell_data_dir, \n",
    "                               image_output_dir = tell_image_dir,\n",
    "                               image_resolution = 150,\n",
    "                               save_images = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809d300-81a1-40eb-be8a-c2958b2880b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Process the EIA-930 historical hourly demand dataset\n",
    "\n",
    "Here we convert the raw EIA-930 hourly electricity demand data for BAs from Excel files to .csv files. The function `process_eia_930_data` also subsets the EIA-930 dataset to only include the desired variables. Note that this step can take a few minutes even when using parallel processing streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042dc367-62c4-4e64-8210-2dac98c7edf4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute the function to pre-proceess the raw EIA-930 data using parallel processing streams:\n",
    "tell.process_eia_930_data(data_input_dir = tell_data_dir,\n",
    "                          n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5149030-e0d7-42e7-b682-07c2faa4df86",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Process the historical population dataset\n",
    "\n",
    "This pre-processing step takes historical county-level population data from the U.S. Census Bureau and computes the total population living within the service territory of each BA. The historical annual populations are then interpolated to an hourly resolution in preparation to use population as input to the MLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508e877-eb82-48f1-9a62-6f0637751e12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute the function to pre-process the historical observed population data for all years from 2015 to 2020:\n",
    "tell.process_ba_population_data(start_year = 2015,\n",
    "                                end_year = 2020,\n",
    "                                data_input_dir = tell_data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf114f-c77e-42b7-bef6-34e71eefcda2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download the sample historical and future meteorology data\n",
    "\n",
    "This pre-processing step relies on another pre-packaged sample dataset containing historical and sample future weather data used in `tell`. This sample forcing data is also available from a [Zenodo data package](https://zenodo.org/record/6354665#.Yi-_PRDMJTY). This section downloads that sample forcing data. The historical and future meteorology is based on IM3 simulations using the Weather Research and Forecasting (WRF) model. Meteorological output from WRF is first averaged into county-level mean values and then population-weighted to create an hourly time series of meteorology for each BA in `tell`.  Note that the sample weather data package will require ~250 MB of storage and can take several minutes to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4931da1-f228-4094-99b2-6d8d11d4fe0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download the TELL sample forcing data package from Zenodo:\n",
    "tell.install_sample_forcing_data(data_dir = tell_data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85275bf1-87d2-4ceb-ba68-ca27e554c57e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compile the historical hourly load, population, and meteorology data \n",
    "\n",
    "In this final pre-processing step we compile the historical load, population, and meteorology data into a single set of .csv files. There is one .csv file generated for each BA in `tell`. These composite .csv files are then used as input to the MLP model training. Note that this step can take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7dc7c7-353e-4918-8561-e6074ab2b43a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the historical load, population, and meteorology data into a single set of .csv files:\n",
    "tell.compile_data(start_year = 2015,\n",
    "                  end_year = 2019,\n",
    "                  data_input_dir = tell_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20187e-1e0d-4a4b-b0b4-6f332fd6ec41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
