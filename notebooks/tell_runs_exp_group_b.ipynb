{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e071b84",
   "metadata": {},
   "source": [
    "# TELL Runs for IM3's Experiment Group B \n",
    "\n",
    "This notebook executes the initial set of runs of the TELL model for IM3's Experiment Group B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86db683a-70a2-4f89-a1d6-4c6d5f180272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the TELL package and information about your operating system:\n",
    "import os \n",
    "import tell\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tell.package_data import get_ba_abbreviations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fce96-4576-4a2d-9db6-4d0be72b3c1d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7cc0f66-ba83-47d4-b161-0b1ad076064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the top-level directory and the subdirectory where the data will be stored:\n",
    "current_dir =  '/Users/burl878/Documents/Research/IMMM/Data/TELL/Production_Runs'\n",
    "tell_data_dir = os.path.join(current_dir, r'tell_data')\n",
    "\n",
    "# If the \"tell_data_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(tell_data_dir):\n",
    "   os.makedirs(tell_data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a037554",
   "metadata": {},
   "source": [
    "## Run the MLP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6b851-29c9-4a1b-a149-ee341f1af5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of BA abbreviations to process:\n",
    "ba_abbrev_list = tell.get_balancing_authority_to_model_dict().keys()\n",
    "\n",
    "scenario_to_process = 'rcp85hotter_ssp5'\n",
    "\n",
    "# Run the MLP prediction step for the list of BAs using parallel processing streams:\n",
    "for year_to_process in range(2020,2100,1):\n",
    "    pdf = tell.predict_batch(target_region_list = ba_abbrev_list,\n",
    "                             year = year_to_process,\n",
    "                             data_dir = os.path.join(tell_data_dir, r'wrf_to_tell_data', scenario_to_process),\n",
    "                             datetime_field_name = 'Time_UTC',\n",
    "                             save_prediction = True,\n",
    "                             prediction_output_directory = os.path.join(tell_data_dir, r'outputs', r'mlp_output', scenario_to_process),\n",
    "                             n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9048639",
   "metadata": {},
   "source": [
    "## Run the Forward Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the TELL model forward in time for a given year in five year increments out to 2100:\n",
    "for year in range(2090,2100,1):\n",
    "    summary_df, ba_time_series_df, state_time_series_df = tell.execute_forward(year_to_process = str(year),\n",
    "                                                                               gcam_target_year = '2095', \n",
    "                                                                               scenario_to_process = 'rcp85hotter_ssp5',\n",
    "                                                                               data_output_dir = '/Users/burl878/Documents/Research/IMMM/Data/TELL/Production_Runs/tell_data/outputs/tell_output',\n",
    "                                                                               gcam_usa_input_dir = '/Users/burl878/Documents/Research/IMMM/Data/TELL/Production_Runs/tell_data/gcamusa_data',\n",
    "                                                                               map_input_dir = '/Users/burl878/Documents/Research/IMMM/Data/TELL/Production_Runs/tell_data/ba_service_territory_data',\n",
    "                                                                               mlp_input_dir = '/Users/burl878/Documents/Research/IMMM/Data/TELL/Production_Runs/tell_data/outputs/mlp_output',\n",
    "                                                                               pop_input_dir = '/Users/burl878/Documents/Research/IMMM/Data/TELL/Production_Runs/tell_data/population_data',\n",
    "                                                                               save_county_data = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47db5ee-9da6-4368-82fb-75820c55fe28",
   "metadata": {},
   "source": [
    "## Visualize the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79cc3caf-cb82-4d99-898c-e735013efb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot the interannual variability for a given BA or state:\n",
    "def plot_load_duration_curve_variability(plot_ba, entity_to_plot: str, top_x_hours: int, scenario_to_plot: str, data_input_dir: str, image_output_dir: str, image_resolution: int, save_images=False):\n",
    "    \"\"\"Plot the interannual variability of the load duration curve for a given BA or state\n",
    "\n",
    "    :param plot_ba:             Set to True if you want to plot the output for BAs\n",
    "    :type plot_ba:              bool\n",
    "\n",
    "    :param entity_to_plot:      BA code or state abbreviation for entity you want to plot\n",
    "    :type entity_to_plot:       str\n",
    "\n",
    "    :param top_x_hours:         Number of peak hours to be included in the load duration curve plot\n",
    "    :type top_x_hours:          int\n",
    "\n",
    "    :param scenario_to_plot:    Scenario you want to plot\n",
    "    :type scenario_to_plot:     str\n",
    "\n",
    "    :param data_input_dir:      Top-level data directory for TELL\n",
    "    :type data_input_dir:       str\n",
    "\n",
    "    :param image_output_dir:    Directory to store the images\n",
    "    :type image_output_dir:     str\n",
    "\n",
    "    :param image_resolution:    Resolution at which you want to save the images in DPI\n",
    "    :type image_resolution:     int\n",
    "\n",
    "    :param save_images:         Set to True if you want to save the images after they're generated\n",
    "    :type save_images:          bool\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the data input directory:\n",
    "    tell_data_input_dir = os.path.join(data_input_dir, r'outputs', r'tell_output', scenario_to_plot)\n",
    "\n",
    "    # Set the image output directory:\n",
    "    image_dir = os.path.join(image_output_dir, scenario_to_plot)\n",
    "\n",
    "    # If the output directory doesn't exist then create it:\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "    \n",
    "    # Make the plot:\n",
    "    plt.figure(figsize=(25, 10))\n",
    "        \n",
    "    for base_year in range(2025,2105,10):\n",
    "        if plot_ba:\n",
    "           for year_delta in range(-5,5,1):\n",
    "               # Read in the 'TELL_Balancing_Authority_Hourly_Load_Data_' .csv file and parse the time variable:\n",
    "               hourly_load_df = pd.read_csv((tell_data_input_dir + '/' + str(base_year) + '/' + 'TELL_Balancing_Authority_Hourly_Load_Data_' + str(base_year + year_delta) + '_Scaled_' + str(base_year) + '.csv'), parse_dates=[\"Time_UTC\"])\n",
    "\n",
    "               # Subset the dataframe to only the BA you want to plot:\n",
    "               subset_df = hourly_load_df.loc[hourly_load_df['BA_Code'] == entity_to_plot]\n",
    "\n",
    "               # Sort the hourly load values from largest to smallest and compute the hourly duration for each value:\n",
    "               load_df_sorted_df = subset_df.sort_values(by=['Scaled_TELL_BA_Load_MWh'], ascending=False)\n",
    "               load_df_sorted_df['Year'] = str(base_year + year_delta)\n",
    "               load_df_sorted_df['Interval'] = 1\n",
    "               load_df_sorted_df['Duration'] = load_df_sorted_df['Interval'].cumsum()\n",
    "                  \n",
    "               # Rename the load variable:\n",
    "               load_df_sorted_df.rename(columns={'Scaled_TELL_BA_Load_MWh': 'Load_MWh'}, inplace=True)\n",
    "            \n",
    "               # Subset and reorder the columns:\n",
    "               output_df = load_df_sorted_df[['Year', 'Duration', 'Load_MWh']]\n",
    "        \n",
    "               # Aggregate the output into a new dataframe:\n",
    "               if year_delta == -5:\n",
    "                  aggregate_output_df = output_df\n",
    "               else:\n",
    "                  aggregate_output_df = pd.concat([aggregate_output_df, output_df])\n",
    "\n",
    "           aggregate_output_df = aggregate_output_df.loc[aggregate_output_df['Duration'] <= top_x_hours]\n",
    "        \n",
    "           if base_year == 2025:\n",
    "              index = 1\n",
    "           else:\n",
    "              index = int(((base_year - 2025)/10) + 1)\n",
    "        \n",
    "           plt.subplot(2,4,index)\n",
    "           for year_delta in range(-5,6,1):\n",
    "               plt.plot(aggregate_output_df['Duration'].loc[aggregate_output_df['Year'] == str(base_year + year_delta)], \n",
    "                        aggregate_output_df['Load_MWh'].loc[aggregate_output_df['Year'] == str(base_year + year_delta)], \n",
    "                        color='gray', linestyle='-', label=('Load: ' + str(base_year + year_delta)), linewidth=1)\n",
    "           plt.plot(aggregate_output_df['Duration'].loc[aggregate_output_df['Year'] == str(base_year)], aggregate_output_df['Load_MWh'].loc[aggregate_output_df['Year'] == str(base_year)],\n",
    "                    color='black', linestyle='-', label='Base Year Load', linewidth=4)\n",
    "           plt.xlim((0,top_x_hours))\n",
    "           plt.xlabel(\"Duration [h]\")\n",
    "           plt.ylabel(\"Hourly Load [MWh]\")\n",
    "           plt.title((entity_to_plot + ' LDCs in ' + str(base_year) + ': ' + scenario_to_plot))\n",
    "        \n",
    "        if plot_ba == False:\n",
    "           for year_delta in range(-5,5,1):\n",
    "               # Read in the 'TELL_State_Summary_Data' .csv file and parse the time variable:\n",
    "               hourly_load_df = pd.read_csv((tell_data_input_dir + '/' + str(base_year) + '/' + 'TELL_State_Hourly_Load_Data_' + str(base_year + year_delta) + '_Scaled_' + str(base_year) + '.csv'), parse_dates=[\"Time_UTC\"])\n",
    "\n",
    "               # Subset the dataframe to only the state you want to plot:\n",
    "               subset_df = hourly_load_df.loc[hourly_load_df['State_Name'] == entity_to_plot]\n",
    "\n",
    "               # Sort the hourly load values from largest to smallest and compute the hourly duration for each value:\n",
    "               load_df_sorted_df = subset_df.sort_values(by=['Scaled_TELL_State_Load_MWh'], ascending=False)\n",
    "               load_df_sorted_df['Year'] = str(base_year + year_delta)\n",
    "               load_df_sorted_df['Interval'] = 1\n",
    "               load_df_sorted_df['Duration'] = load_df_sorted_df['Interval'].cumsum()\n",
    "                  \n",
    "               # Rename the load variable:\n",
    "               load_df_sorted_df.rename(columns={'Scaled_TELL_State_Load_MWh': 'Load_MWh'}, inplace=True)\n",
    "            \n",
    "               # Subset and reorder the columns:\n",
    "               output_df = load_df_sorted_df[['Year', 'Duration', 'Load_MWh']]\n",
    "        \n",
    "               # Aggregate the output into a new dataframe:\n",
    "               if year_delta == -5:\n",
    "                  aggregate_output_df = output_df\n",
    "               else:\n",
    "                  aggregate_output_df = pd.concat([aggregate_output_df, output_df])\n",
    "\n",
    "           aggregate_output_df = aggregate_output_df.loc[aggregate_output_df['Duration'] <= top_x_hours]\n",
    "        \n",
    "           if base_year == 2025:\n",
    "              index = 1\n",
    "           else:\n",
    "              index = int(((base_year - 2025)/10) + 1)\n",
    "        \n",
    "           plt.subplot(2,4,index)\n",
    "           for year_delta in range(-5,6,1):\n",
    "               plt.plot(aggregate_output_df['Duration'].loc[aggregate_output_df['Year'] == str(base_year + year_delta)], \n",
    "                        aggregate_output_df['Load_MWh'].loc[aggregate_output_df['Year'] == str(base_year + year_delta)], \n",
    "                        color='gray', linestyle='-', label=('Load: ' + str(base_year + year_delta)), linewidth=1)\n",
    "           plt.plot(aggregate_output_df['Duration'].loc[aggregate_output_df['Year'] == str(base_year)], aggregate_output_df['Load_MWh'].loc[aggregate_output_df['Year'] == str(base_year)],\n",
    "                    color='black', linestyle='-', label='Base Year Load', linewidth=4)\n",
    "           plt.xlim((0,top_x_hours))\n",
    "           plt.xlabel(\"Duration [h]\")\n",
    "           plt.ylabel(\"Hourly Load [MWh]\")\n",
    "           plt.title((entity_to_plot + ' LDCs in ' + str(base_year) + ': ' + scenario_to_plot))\n",
    "\n",
    "    # If the \"save_images\" flag is set to true then save the plot to a .png file:\n",
    "    if save_images == True:\n",
    "       if plot_ba:\n",
    "          ba_name = entity_to_plot\n",
    "          filename = ('TELL_BA_LDC_Variability_' + ba_name + '_' + scenario_to_plot + '.png')\n",
    "          plt.savefig(os.path.join(image_dir, filename), dpi=image_resolution, bbox_inches='tight', facecolor='white')   \n",
    "       if plot_ba == False:\n",
    "          state_name = entity_to_plot\n",
    "          state_name = state_name.replace(\" \", \"_\")\n",
    "          filename = ('TELL_State_LDC_Variability_' + state_name + '_' + scenario_to_plot + '.png')\n",
    "          plt.savefig(os.path.join(image_dir, filename), dpi=image_resolution, bbox_inches='tight', facecolor='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175a3e4-9ffb-4439-bcdd-42c6220f50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of BA abbreviations to process:\n",
    "#ba_names = get_ba_abbreviations()\n",
    "ba_names = ['CISO', 'PJM', 'ERCO', 'ISNE', 'MISO', 'AZPS']\n",
    "\n",
    "# Loop over the list of BAs and make the LDC plot for each BA:\n",
    "for i in ba_names:\n",
    "    plot_load_duration_curve_variability(plot_ba = True,\n",
    "                                         entity_to_plot = i, \n",
    "                                         top_x_hours = 168, \n",
    "                                         scenario_to_plot = 'rcp85hotter_ssp5', \n",
    "                                         data_input_dir = tell_data_dir,\n",
    "                                         image_output_dir = '/Users/burl878/Documents/code_repos/tell/tell/production_visualizations', \n",
    "                                         image_resolution = 50, \n",
    "                                         save_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aac3bf-6f36-4cf0-92ba-043c0f399445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.4_tell",
   "language": "python",
   "name": "py3.9.4_tell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
