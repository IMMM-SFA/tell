{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e071b84",
   "metadata": {},
   "source": [
    "# Welcome to the TELL Quickstarter! \n",
    "\n",
    "### **`tell` is an open-source Python package for predicting future electricty load in the Lower 48 United States.**\n",
    "\n",
    "## A little about `tell`\n",
    "\n",
    "The Total ELectricity Load (TELL) model provides a framework that integrates aspects of both short- and long-term predictions of electricity demand in a coherent and scalable way. `tell` takes as input gridded hourly time-series of meteorology and uses the temporal variations in weather to predict hourly profiles of total electricity demand for every county in the lower 48 United States using a multilayer perceptron (MLP) approach. Hourly predictions from `tell` are then scaled to match the annual state-level total electricity loads predicted by the U.S. version of the Global Change Analysis Model (GCAM-USA). GCAM-USA is designed to capture the long-term co-evolution of the human-Earth system. Using this unique approach allows tell to reflect both changes in the shape of the load profile due to variations in weather and climate and the long-term evolution of energy demand due to changes in population, technology, and economics. `tell` is unique from other probabilistic load forecasting models in that it features an explicit spatial component that allows us to relate predicted loads to where they would occur spatially within a grid operations model.\n",
    "\n",
    "## Lets get started! \n",
    "\n",
    "In this quickstarter we will walk through a subset of the data used in `tell`, starting with importing the package and ending with data visualization. This allows the user to walk through the entire `tell` package in a matter of minutes. If you have more questions please feel free to visit the [Read the Docs](https://immm-sfa.github.io/tell/index.html) site for `tell`.\n",
    "\n",
    "### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e9c75a-eb13-4868-9c2d-de6a85920592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "\n",
    "import tell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38969d32-9abe-4a0c-9794-744c3dfbb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO -- should investigate each warning and mitigate, rather than using this block\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fce96-4576-4a2d-9db6-4d0be72b3c1d",
   "metadata": {},
   "source": [
    "### Install package data\n",
    "\n",
    "**NOTE: The package data will require approximately 1.4 GB of storage.**\n",
    "\n",
    "Set the local directory where you would like to store the package data and run the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7cc0f66-ba83-47d4-b161-0b1ad076064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory if one does not exist\n",
    "current_dir =  os.path.dirname(os.getcwd())\n",
    "current_dir =  os.path.join(os.path.dirname(os.getcwd()), r'tell_data')\n",
    "\n",
    "raw_data_dir = os.path.join(current_dir, r'raw_data')\n",
    "\n",
    "if not os.path.exists(raw_data_dir):\n",
    "   os.makedirs(raw_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8840888f-e1b9-43c6-9b86-d4682edb2c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading example data for tell version 3.0.0...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Download the raw data from the Zenodo package\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstall_package_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_data_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/github/tell/tell/install_supplement.py:90\u001b[0m, in \u001b[0;36minstall_package_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m\"\"\"Download and unpack example data supplement from Zenodo that matches the current installed\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03mtell distribution.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m:param data_dir:                    Optional.  Full path to the directory you wish to store the data in.  Default is\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m                                    to install it in data directory of the package.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m:type data_dir:                     str\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m zen \u001b[38;5;241m=\u001b[39m InstallSupplement(data_dir\u001b[38;5;241m=\u001b[39mdata_dir)\n\u001b[0;32m---> 90\u001b[0m \u001b[43mzen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_zenodo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/github/tell/tell/install_supplement.py:51\u001b[0m, in \u001b[0;36mInstallSupplement.fetch_zenodo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# retrieve content from URL\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading example data for tell version \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(current_version))\n\u001b[0;32m---> 51\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_link\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(BytesIO(r\u001b[38;5;241m.\u001b[39mcontent)) \u001b[38;5;28;01mas\u001b[39;00m zipped:\n\u001b[1;32m     54\u001b[0m \n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# extract each file in the zipped dir to the project\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m zipped\u001b[38;5;241m.\u001b[39mnamelist():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/envs/xtest/lib/python3.9/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/envs/xtest/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/envs/xtest/lib/python3.9/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/envs/xtest/lib/python3.9/site-packages/requests/sessions.py:687\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 687\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/envs/xtest/lib/python3.9/site-packages/requests/models.py:838\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 838\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/envs/xtest/lib/python3.9/site-packages/requests/models.py:760\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 760\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    761\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/envs/xtest/lib/python3.9/site-packages/urllib3/response.py:576\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 576\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    579\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/envs/xtest/lib/python3.9/site-packages/urllib3/response.py:519\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     cache_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    521\u001b[0m         amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[1;32m    522\u001b[0m     ):  \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/http/client.py:455\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 455\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/http/client.py:499\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    494\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Download the raw data from the Zenodo package\n",
    "tell.install_package_data(data_dir=raw_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e532316a-d350-4eae-ae9a-1679da2f6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the start and end year for processing\n",
    "start_year = 2015\n",
    "end_year = 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b10c8-5872-42a9-84ae-ba09ef4a90c2",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing for TELL\n",
    "\n",
    "In the next few code blocks we will load and manipulate the nescessary data for the `tell`  package. This consists of hourly load, population and meterology for the CONUS, which will be loaded in from raw data sources, manipulated and then compiled together to use as input for the MLP model. Please follow the steps below to produce the hourly input data, if you have already finished this step you can proceed to **2. Model training and prediction**\n",
    "    \n",
    "### 1.0 Spaitally mapping the Balancing Authorities (BAs)\n",
    "\n",
    "The code chunk below brings in the unique spatial component of `tell`, where we map the Balancing Authorities (BAs) to the Federal Information Processing Standard Publication (FIPS) codes. This allows us to assign load where it occurs spatially within the CONUS.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab18f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIPS to BA code mapping ##\n",
    "tell.map_fips_codes(start_year, end_year,raw_data_dir, current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8412d0",
   "metadata": {},
   "source": [
    "### 1.1 Hourly load\n",
    "\n",
    "Here we load in the raw EIA 930 hourly load profiles for all Balancing Authorities (BAs), select the desired columns only, and then output the hourly load as CSV files to be compiled later with population and meteorlogy to be fed to the MLP model downstream to predict future load.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e6732-9c6f-4bd8-956b-4686ad60652c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the data input and output directories:\n",
    "eia_930_input_dir = raw_data_dir\n",
    "eia_930_output_dir = os.path.join(current_dir, r'outputs', r'hourly_ba_load')\n",
    "if not os.path.exists(eia_930_output_dir):\n",
    "   os.makedirs(eia_930_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f6616-3de4-4a57-a3d9-75bf5adbe6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the hourly load data\n",
    "tell.process_eia_930(eia_930_input_dir, eia_930_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274fd1f-de15-4987-b9fe-c30b2af57c4e",
   "metadata": {},
   "source": [
    "### 1.2 Population data\n",
    "\n",
    "For this data processing step we will load in the annual population by FIPS code, merge by FIPS code to get the correspondng BA number, sum by  year and BA number and then interpolate the annual population to hourly population in order to feed it to the MLP model downstream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb4ead-6a55-4b42-bc0a-80e849aef2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data input and output directories:\n",
    "pop_input_dir = raw_data_dir\n",
    "map_input_dir = os.path.join(current_dir, r'outputs', r'fips_mapping_files')\n",
    "pop_output_dir =  os.path.join(current_dir, r'outputs', r'hourly_population')\n",
    "if not os.path.exists(pop_output_dir):\n",
    "   os.makedirs(pop_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c48a208-9fcc-4325-ab1b-cfce623bab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tell.ba_pop_interpolate(map_input_dir, pop_input_dir, pop_output_dir, start_year, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a3913-25ec-4d9f-8544-ecff68e4d467",
   "metadata": {},
   "source": [
    "### 1.3 Meteorology data\n",
    "\n",
    "Here we use the <im3components> package to load in the WRF meteorology data, average WRF meteorology by county and then aggregate them into annual hourly time-series of population-weighted meteorology for each balancing authority (BA). All times are in UTC. Missing values are reported as -9999. First we download a subset of the wrf data from the Zenodo package to work with in this quickstarter. For thi subset we choose the target year of 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9245d-c18b-4a13-8f1d-1933b22fcac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input directory meteorology data #\n",
    "wrf_input_dir =  os.path.join(current_dir, r'raw_data', r'wrf')\n",
    "if not os.path.exists(wrf_input_dir):\n",
    "   os.makedirs(wrf_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba953ea1-8e71-4a99-86ba-81b27e4534d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the raw wrf data from the Zenodo package\n",
    "tell.install_sample_data(data_dir = wrf_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fbf33-7fd3-4536-be53-919daf808784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory meteorology data #\n",
    "wrf_output_dir =  os.path.join(current_dir, r'outputs', r'hourly_meteorology')\n",
    "if not os.path.exists(wrf_output_dir):\n",
    "   os.makedirs(wrf_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17766cd0-0067-4713-aecd-04be7bdfe357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target year \n",
    "target_yr = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7b310-7002-41f9-9a4c-8491df54e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process wrf data to put into right date format\n",
    "tell.process_wrf(wrf_input_dir, wrf_output_dir, target_yr, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f5df8-16d9-400c-acdf-2f0d34b971f2",
   "metadata": {},
   "source": [
    "### 1.4 Compile hourly load, population and meteorology data \n",
    "\n",
    "Here we compile all the data processing steps above for hourly load (EIA 930), population (county FIPS) and meteorology (WRF) to get a final cleaned up dataset to use as an input to the MLP model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef7700-4eee-4d02-a8f9-a2ecca806943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to store the compiled data\n",
    "compile_output_dir =  os.path.join(current_dir, r'outputs', r'compiled_data')\n",
    "if not os.path.exists(compile_output_dir):\n",
    "   os.makedirs(compile_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762a650-1304-4004-b5cd-821a72a92385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target year for WRF data\n",
    "target_yr = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6d6f4-4889-4c76-9375-9f37d365dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the hourly load data, population data, and wrf climate data by date\n",
    "tell.compile_data(eia_930_output_dir, pop_output_dir, wrf_output_dir, target_yr, compile_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a037554",
   "metadata": {},
   "source": [
    "## 2. Model training and prediction\n",
    "\n",
    "This step takes the data processed and compiled above and runs a multilayer perceptron (MLP) model to predict future hourly load. Start-time is the start-time for analysis, end-time is the end time for analysis and spilt-time is the timestamp splitting train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccddc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory for the mlp output\n",
    "mlp_output_dir =  os.path.join(current_dir, r'outputs', r'mlp_output')\n",
    "if not os.path.exists(mlp_output_dir):\n",
    "   os.makedirs(mlp_output_dir)\n",
    "\n",
    "# specify the parameters of the MLP model\n",
    "batch_run = True\n",
    "target_ba_list = None\n",
    "generate_plots = True\n",
    "start_time = \"2019-01-01 00:00:00\"\n",
    "end_time = \"2019-12-31 23:00:00\"\n",
    "split_time = \"2019-06-01 00:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac69fd-6962-4302-ab7f-256d9ad733eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "tell.predict(compile_output_dir ,\n",
    "            mlp_output_dir,\n",
    "            start_time = start_time,\n",
    "            end_time = end_time,\n",
    "            split_time = split_time,\n",
    "            batch_run = batch_run,\n",
    "            target_ba_list = target_ba_list,\n",
    "            generate_plots = generate_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9048639",
   "metadata": {},
   "source": [
    "## 3. Model forward execution\n",
    "\n",
    "This script takes the .csv files produced by the TELL MLP model and distributes the predicted load to the counties that each balancing authority (BA) operates in. The county-level hourly loads are then summed to the state-level and scaled to match the state-level annual loads produced by GCAM-USA. Three sets of output files are generated: county-level hourly loads, state-level hourly loads, and hourly loads for each BA. There is one additional summary output file that includes state-level annual loads from TELL and GCAM-USA as well as the scaling factors.\n",
    "\n",
    "Please set the directories below to your local machine preferences and run the tell.execute_forward function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year and GCAM-USA scenario to process:\n",
    "year_to_process = '2020'\n",
    "gcam_usa_scenario = 'scenario_name'\n",
    "\n",
    "# Set the data input and output directories:\n",
    "mlp_input_dir = os.path.join(current_dir, 'outputs', 'mlp_output')\n",
    "ba_geolocation_input_dir = os.path.join(current_dir, 'outputs', 'fips_mapping_files')\n",
    "gcam_usa_input_dir = os.path.join(current_dir, 'raw_data')\n",
    "data_output_dir = os.path.join(current_dir, 'outputs', 'forward_output', f'{year_to_process}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7443cd7d-7ab6-4c54-869c-cff129597983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the MLP model forward in time and\n",
    "tell.execute_forward(year_to_process, mlp_input_dir, ba_geolocation_input_dir,\n",
    "                     pop_input_dir, gcam_usa_input_dir, data_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae90672",
   "metadata": {},
   "source": [
    "## 4. Model visualization\n",
    "\n",
    "Below are a few select model visualizations to check on model performance for select states and BAs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data input and output directories:\n",
    "data_input_dir = os.path.join(current_dir, 'outputs', 'forward_output')\n",
    "image_output_dir = os.path.join(current_dir, r'outputs', r'image_output')\n",
    "shapefile_input_dir = raw_data_dir\n",
    "\n",
    "# Set the year of TELL output to visualize:\n",
    "year_to_plot = '2020'\n",
    "\n",
    "# Choose whether or not to save the images and set the image resolution:\n",
    "save_images = 0 # (1 = Yes)\n",
    "image_resolution = 150 # (dpi)\n",
    "\n",
    "sample_state = 'California'\n",
    "sample_ba = 'ERCO'\n",
    "\n",
    "# If you want to save the images, check that the image output directory exist and if not then create it:\n",
    "if save_images == 1:\n",
    "   if os.path.exists((image_output_dir + year_to_plot)) == False:\n",
    "      os.mkdir((image_output_dir + year_to_plot))\n",
    "\n",
    "# Plot a map of the state scaling factors:\n",
    "tell.plot_state_scaling_factors(shapefile_input_dir, data_input_dir, year_to_plot, save_images, image_resolution,\n",
    "                                image_output_dir)\n",
    "\n",
    "# Plot the state annual total loads from GCAM-USA and TELL:\n",
    "tell.plot_state_annual_total_loads(state_summary_df, year_to_plot, save_images, image_resolution, image_output_dir)\n",
    "\n",
    "# Plot the time-series of total hourly loads for a given state by specifying either the state name or FIPS code:\n",
    "tell.plot_state_load_time_series({state}, state_hourly_load_df, year_to_plot, save_images, image_resolution,\n",
    "                                 image_output_dir)\n",
    "\n",
    "# Plot the load duration curve for a given state by specifying either the state name or FIPS code:\n",
    "tell.plot_state_load_duration_curve({state}, state_hourly_load_df, year_to_plot, save_images, image_resolution,\n",
    "                                    image_output_dir)\n",
    "\n",
    "# Plot the time-series of total hourly loads for a given BA by specifying either the BA abbreviation or BA number:\n",
    "tell.plot_ba_load_time_series({sample_ba}, ba_hourly_load_df, year_to_plot, save_images, image_resolution, image_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5c303-a15e-4c9c-b97a-462f30618328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtest",
   "language": "python",
   "name": "xtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
