{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e071b84",
   "metadata": {},
   "source": [
    "# Welcome to the TELL Quickstarter! \n",
    "\n",
    "### **`tell` is an open-source Python package for predicting future electricty load in the Lower 48 United States.**\n",
    "\n",
    "## A little about `tell`\n",
    "\n",
    "The Total ELectricity Load (TELL) model provides a framework that integrates aspects of both short- and long-term predictions of electricity demand in a coherent and scalable way. `tell` takes as input gridded hourly time-series of meteorology and uses the temporal variations in weather to predict hourly profiles of total electricity demand for every county in the lower 48 United States using a multilayer perceptron (MLP) approach. Hourly predictions from `tell` are then scaled to match the annual state-level total electricity loads predicted by the U.S. version of the Global Change Analysis Model (GCAM-USA). GCAM-USA is designed to capture the long-term co-evolution of the human-Earth system. Using this unique approach allows tell to reflect both changes in the shape of the load profile due to variations in weather and climate and the long-term evolution of energy demand due to changes in population, technology, and economics. `tell` is unique from other probabilistic load forecasting models in that it features an explicit spatial component that allows us to relate predicted loads to where they would occur spatially within a grid operations model.\n",
    "\n",
    "## Lets get started! \n",
    "\n",
    "In this quickstarter we will walk through a subset of the data used in `tell`, starting with importing the package and ending with data visualization. This allows the user to walk through the entire `tell` package in a matter of minutes. If you have more questions please feel free to visit the [Read the Docs](https://immm-sfa.github.io/tell/index.html) site for `tell`.\n",
    "\n",
    "### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9c75a-eb13-4868-9c2d-de6a85920592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tell\n",
    "import os \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38969d32-9abe-4a0c-9794-744c3dfbb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO -- should investigate each warning and mitigate, rather than using this block\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566fce96-4576-4a2d-9db6-4d0be72b3c1d",
   "metadata": {},
   "source": [
    "### Install package data\n",
    "\n",
    "**NOTE: The package data will require approximately 1.4 GB of storage.**\n",
    "\n",
    "Set the local directory where you would like to store the package data and run the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc0f66-ba83-47d4-b161-0b1ad076064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to store raw data\n",
    "current_dir =  os.path.dirname(os.getcwd())\n",
    "current_dir =  os.path.join(os.path.dirname(os.getcwd()), r'tell_valid')\n",
    "raw_data_dir = os.path.join(current_dir, r'raw_data')\n",
    "if not os.path.exists(raw_data_dir):\n",
    "   os.makedirs(raw_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840888f-e1b9-43c6-9b86-d4682edb2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the raw data from the Zenodo package\n",
    "tell.install_package_data(data_dir = raw_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532316a-d350-4eae-ae9a-1679da2f6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the start and end year for processing\n",
    "start_year = 2015\n",
    "end_year = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b10c8-5872-42a9-84ae-ba09ef4a90c2",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing for TELL\n",
    "\n",
    "In the next few code blocks we will load and manipulate the nescessary data for the `tell`  package. This consists of hourly load, population and meterology for the CONUS, which will be loaded in from raw data sources, manipulated and then compiled together to use as input for the MLP model. Please follow the steps below to produce the hourly input data, if you have already finished this step you can proceed to **2. Model training and prediction**\n",
    "    \n",
    "### 1.0 Spaitally mapping the Balancing Authorities (BAs)\n",
    "\n",
    "The code chunk below brings in the unique spatial component of `tell`, where we map the Balancing Authorities (BAs) to the Federal Information Processing Standard Publication (FIPS) codes. This allows us to assign load where it occurs spatially within the CONUS.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab18f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIPS to BA code mapping ##\n",
    "tell.map_fips_codes(start_year, end_year,raw_data_dir, current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8412d0",
   "metadata": {},
   "source": [
    "### 1.1 Hourly load\n",
    "\n",
    "Here we load in the raw EIA 930 hourly load profiles for all Balancing Authorities (BAs), select the desired columns only, and then output the hourly load as CSV files to be compiled later with population and meteorlogy to be fed to the MLP model downstream to predict future load.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e6732-9c6f-4bd8-956b-4686ad60652c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the data input and output directories:\n",
    "eia_930_input_dir = raw_data_dir\n",
    "eia_930_output_dir = os.path.join(current_dir, r'outputs', r'hourly_ba_load')\n",
    "if not os.path.exists(eia_930_output_dir):\n",
    "   os.makedirs(eia_930_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f6616-3de4-4a57-a3d9-75bf5adbe6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the hourly load data\n",
    "tell.process_eia_930(eia_930_input_dir, eia_930_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274fd1f-de15-4987-b9fe-c30b2af57c4e",
   "metadata": {},
   "source": [
    "### 1.2 Population data\n",
    "\n",
    "For this data processing step we will load in the annual population by FIPS code, merge by FIPS code to get the correspondng BA number, sum by  year and BA number and then interpolate the annual population to hourly population in order to feed it to the MLP model downstream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb4ead-6a55-4b42-bc0a-80e849aef2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data input and output directories:\n",
    "pop_input_dir = raw_data_dir\n",
    "map_input_dir = os.path.join(current_dir, r'outputs', r'fips_mapping_files')\n",
    "pop_output_dir =  os.path.join(current_dir, r'outputs', r'hourly_population')\n",
    "if not os.path.exists(pop_output_dir):\n",
    "   os.makedirs(pop_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c48a208-9fcc-4325-ab1b-cfce623bab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tell.ba_pop_interpolate(map_input_dir, pop_input_dir, pop_output_dir, start_year, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a3913-25ec-4d9f-8544-ecff68e4d467",
   "metadata": {},
   "source": [
    "### 1.3 Meteorology data\n",
    "\n",
    "Here we use the <im3components> package to load in the WRF meteorology data, average WRF meteorology by county and then aggregate them into annual hourly time-series of population-weighted meteorology for each balancing authority (BA). All times are in UTC. Missing values are reported as -9999. First we download a subset of the wrf data from the Zenodo package to work with in this quickstarter. For thi subset we choose the target year of 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9245d-c18b-4a13-8f1d-1933b22fcac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input directory meteorology data #\n",
    "wrf_input_dir =  os.path.join(current_dir, r'raw_data', r'wrf')\n",
    "if not os.path.exists(wrf_input_dir):\n",
    "   os.makedirs(wrf_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba953ea1-8e71-4a99-86ba-81b27e4534d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the raw wrf data from the Zenodo package\n",
    "tell.install_sample_data(data_dir = wrf_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fbf33-7fd3-4536-be53-919daf808784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory meteorology data #\n",
    "wrf_output_dir =  os.path.join(current_dir, r'outputs', r'hourly_meteorology')\n",
    "if not os.path.exists(wrf_output_dir):\n",
    "   os.makedirs(wrf_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17766cd0-0067-4713-aecd-04be7bdfe357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target year \n",
    "target_yr = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7b310-7002-41f9-9a4c-8491df54e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process wrf data to put into right date format\n",
    "tell.process_wrf(wrf_input_dir, wrf_output_dir, target_yr, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f5df8-16d9-400c-acdf-2f0d34b971f2",
   "metadata": {},
   "source": [
    "### 1.4 Compile hourly load, population and meteorology data \n",
    "\n",
    "Here we compile all the data processing steps above for hourly load (EIA 930), population (county FIPS) and meteorology (WRF) to get a final cleaned up dataset to use as an input to the MLP model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef7700-4eee-4d02-a8f9-a2ecca806943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to store the compiled data\n",
    "compile_output_dir =  os.path.join(current_dir, r'outputs', r'compiled_data')\n",
    "if not os.path.exists(compile_output_dir):\n",
    "   os.makedirs(compile_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762a650-1304-4004-b5cd-821a72a92385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target year for WRF data\n",
    "target_yr = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6d6f4-4889-4c76-9375-9f37d365dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the hourly load data, population data, and wrf climate data by date\n",
    "tell.compile_data(eia_930_output_dir, pop_output_dir, wrf_output_dir, target_yr, compile_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a037554",
   "metadata": {},
   "source": [
    "## 2. Model training and prediction\n",
    "\n",
    "This step takes the data processed and compiled above and runs a multilayer perceptron (MLP) model to predict future hourly load. Start-time is the start-time for analysis, end-time is the end time for analysis and spilt-time is the timestamp splitting train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccddc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directory for the mlp output\n",
    "mlp_output_dir =  os.path.join(current_dir, r'outputs', r'mlp_output')\n",
    "if not os.path.exists(mlp_output_dir):\n",
    "   os.makedirs(mlp_output_dir)\n",
    "\n",
    "# specify the parameters of the MLP model\n",
    "batch_run = True\n",
    "target_ba_list = None\n",
    "generate_plots = True\n",
    "start_time = \"2019-01-01 00:00:00\"\n",
    "end_time = \"2019-12-31 23:00:00\"\n",
    "split_time = \"2019-06-01 00:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac69fd-6962-4302-ab7f-256d9ad733eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "tell.predict(compile_output_dir ,\n",
    "            mlp_output_dir,\n",
    "            start_time = start_time,\n",
    "            end_time = end_time,\n",
    "            split_time = split_time,\n",
    "            batch_run = batch_run,\n",
    "            target_ba_list = target_ba_list,\n",
    "            generate_plots = generate_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9048639",
   "metadata": {},
   "source": [
    "## 3. Model forward execution\n",
    "\n",
    "This script takes the .csv files produced by the TELL MLP model and distributes the predicted load to the counties that each balancing authority (BA) operates in. The county-level hourly loads are then summed to the state-level and scaled to match the state-level annual loads produced by GCAM-USA. Three sets of output files are generated: county-level hourly loads, state-level hourly loads, and hourly loads for each BA. There is one additional summary output file that includes state-level annual loads from TELL and GCAM-USA as well as the scaling factors.\n",
    "\n",
    "Please set the directories below to your local machine preferences and run the tell.execute_forward function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04afab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year and GCAM-USA scenario to process:\n",
    "year_to_process = '2020'\n",
    "gcam_usa_scenario = 'scenario_name'\n",
    "\n",
    "# Set the data input and output directories:\n",
    "mlp_input_dir = os.path.join(current_dir, 'outputs', 'mlp_output')\n",
    "ba_geolocation_input_dir = os.path.join(current_dir, 'outputs', 'fips_mapping_files')\n",
    "gcam_usa_input_dir = os.path.join(current_dir, 'raw_data')\n",
    "data_output_dir = os.path.join(current_dir, 'outputs', 'forward_output', f'{year_to_process}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7443cd7d-7ab6-4c54-869c-cff129597983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the MLP model forward in time and\n",
    "tell.execute_forward(year_to_process, mlp_input_dir, ba_geolocation_input_dir,\n",
    "                     pop_input_dir, gcam_usa_input_dir, data_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae90672",
   "metadata": {},
   "source": [
    "## 4. Model visualization\n",
    "\n",
    "Below are a few select model visualizations to check on model performance for select states and BAs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data input and output directories:\n",
    "data_input_dir = os.path.join(current_dir, 'outputs', 'forward_output')\n",
    "image_output_dir = os.path.join(current_dir, r'outputs', r'image_output')\n",
    "shapefile_input_dir = raw_data_dir\n",
    "\n",
    "# Set the year of TELL output to visualize:\n",
    "year_to_plot = '2020'\n",
    "\n",
    "# Choose whether or not to save the images and set the image resolution:\n",
    "save_images = 0 # (1 = Yes)\n",
    "image_resolution = 150 # (dpi)\n",
    "\n",
    "sample_state = 'California'\n",
    "sample_ba = 'ERCO'\n",
    "\n",
    "# If you want to save the images, check that the image output directory exist and if not then create it:\n",
    "if save_images == 1:\n",
    "   if os.path.exists((image_output_dir + year_to_plot)) == False:\n",
    "      os.mkdir((image_output_dir + year_to_plot))\n",
    "\n",
    "# Plot a map of the state scaling factors:\n",
    "tell.plot_state_scaling_factors(shapefile_input_dir, data_input_dir, year_to_plot, save_images, image_resolution,\n",
    "                                image_output_dir)\n",
    "\n",
    "# Plot the state annual total loads from GCAM-USA and TELL:\n",
    "tell.plot_state_annual_total_loads(state_summary_df, year_to_plot, save_images, image_resolution, image_output_dir)\n",
    "\n",
    "# Plot the time-series of total hourly loads for a given state by specifying either the state name or FIPS code:\n",
    "tell.plot_state_load_time_series({state}, state_hourly_load_df, year_to_plot, save_images, image_resolution,\n",
    "                                 image_output_dir)\n",
    "\n",
    "# Plot the load duration curve for a given state by specifying either the state name or FIPS code:\n",
    "tell.plot_state_load_duration_curve({state}, state_hourly_load_df, year_to_plot, save_images, image_resolution,\n",
    "                                    image_output_dir)\n",
    "\n",
    "# Plot the time-series of total hourly loads for a given BA by specifying either the BA abbreviation or BA number:\n",
    "tell.plot_ba_load_time_series({sample_ba}, ba_hourly_load_df, year_to_plot, save_images, image_resolution, image_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5c303-a15e-4c9c-b97a-462f30618328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tell",
   "language": "python",
   "name": "tell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
