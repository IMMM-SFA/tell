{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e343b2f-e0fd-42e8-b41a-6094f8fb6c4e",
   "metadata": {},
   "source": [
    "## Evaluation and Calibration of the Empirical Models in TELL\n",
    "\n",
    "This notebook is meant to be a landing page for exploring the empirical models that underpin `tell`. It will set up the meteorological variables we use and analyze different aspects of the model development and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b242f29e-982a-4efb-ad1f-172145688b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the TELL package and information about your operating system:\n",
    "import os \n",
    "import tell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f8864-631b-4683-ad39-51639f1d24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the current working directory, the \"tell_data\" directory where the data will is stored, and the image output directory:\n",
    "current_dir =  os.path.join(os.path.dirname(os.getcwd()))\n",
    "tell_data_dir = os.path.join(current_dir, r'tell_data')\n",
    "tell_image_dir = os.path.join(tell_data_dir, r'outputs', r'visualizations', r'mlp_evaluation')\n",
    "\n",
    "# If the \"tell_image_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(tell_image_dir):\n",
    "   os.makedirs(tell_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a0c62-d668-4182-9b44-60edc9f0f606",
   "metadata": {},
   "source": [
    "### Variable Correlations\n",
    "\n",
    "The first thing we'll look at is the relationship between the predictive variables in `tell` and the historical electricity demand for different Balancing Authorities (BAs). The function below plots the correlation between the different variables in the historical observed data that underpins `tell`. In general, demand is fairly well correlated with most of the meteorological variables, with the strongest dependency being on 2-m air temperature (T2). The stength of the correlations varies significantly from BA-to-BA. Demand in some BAs is closely tied to variations in weather (e.g., NEVP, ERCO, FPL). In more moderate climates (e.g., SCL, BPAT) the relationships are weaker. This pattern is useful for interpreting the performance of the empircal models in `tell`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6ccc6-dcc5-411a-a4db-6f1924638803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation between predictive variables in TELL and the historical demand in a given BA. Note that if you set the 'ba_to_plot' variable to \"All\" the function \n",
    "# will compute and plot the average correlation across all BAs:\n",
    "tell.plot_ba_variable_correlations(ba_to_plot = 'NEVP', \n",
    "                                   data_input_dir = tell_data_dir,\n",
    "                                   image_output_dir = tell_image_dir,\n",
    "                                   image_resolution = 150,\n",
    "                                   save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10fbdbb-688f-4982-a23f-a03e6cf5f359",
   "metadata": {},
   "source": [
    "### Empirical Model Training\n",
    "\n",
    "Next we'll train the `tell` models using the standard settings found in the `mlp_settings.yml` file. By default, the `tell` multi-layer perceptron (MLP) models are trained on historical weather and load data from 2016-2018 and evaluated using data from 2019. In addition to the MLP models, `tell` trains a linear model for each BA that uses the hourly evolution of total population within the BA's service territory to predict the residuals from the MLP models. The quantitative effect of these linar models is evaluated later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c9fb4-b3f3-454f-add1-abdab4de9f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the empirical models using the standard settings:\n",
    "prediction_df, validation_df = tell.train_batch(target_region_list = (tell.get_balancing_authority_to_model_dict().keys()),\n",
    "                                                data_dir = os.path.join(tell_data_dir, r'outputs', r'compiled_historical_data'),\n",
    "                                                n_jobs = -1)\n",
    "        \n",
    "# View the validation dataframe that contains error statistics for the trained models:\n",
    "validation_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809d300-81a1-40eb-be8a-c2958b2880b3",
   "metadata": {},
   "source": [
    "### Empirical Model Evaluation\n",
    "\n",
    "After training the models, we'll visualize their performance by plotting the error characteristics for each of the BAs in `tell`. In general, the default training settings results in models that perform quite well. 76% (41/54) of the BAs have an R2 value greater than 0.75 while 89% (48/54) have a MAPE under 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042dc367-62c4-4e64-8210-2dac98c7edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the statistical performance (e.g., RMS_ABS, RMS_NORM, MAPE, or R2) of the predictive models across all the BAs in TELL:\n",
    "tell.plot_mlp_summary_statistics(validation_df, \n",
    "                                 image_output_dir = tell_image_dir,\n",
    "                                 image_resolution = 150,\n",
    "                                 save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5149030-e0d7-42e7-b682-07c2faa4df86",
   "metadata": {},
   "source": [
    "It's illustrative to look at the error metrics as a function of load. To do this, we calculate the mean hourly load for each BA during the evaluation year and then plot the error statistics as a function of that mean load. Analyzing the data in this way demonstrates that the BAs with the poorly performing emprical models are almost universally the smaller BAs. The largest BAs, which are critically important for the overall demand on the grid, generally perform quite well. Of the 10 BAs with the largest mean demand, 9/10 have a MAPE value under 5% and an R2 value greater than 0.85. Conversely, of the 10 worst performing BAs (judged by their MAPE value), 7/10 have an average hourly load less than 1200 MWh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508e877-eb82-48f1-9a62-6f0637751e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the statistical performance (e.g., RMS_ABS, RMS_NORM, MAPE, or R2) of the predictive models as a function of mean load for each BA and update the validation dataframe:\n",
    "validation_df = tell.plot_mlp_errors_vs_load(prediction_df, \n",
    "                                             validation_df, \n",
    "                                             image_output_dir = tell_image_dir,\n",
    "                                             image_resolution = 150,\n",
    "                                             save_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48813f16-0333-40b8-b939-37e2e2b28526",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.sort_values(by='Mean_Load_MWh', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4931da1-f228-4094-99b2-6d8d11d4fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.sort_values(by='MAPE', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85275bf1-87d2-4ceb-ba68-ca27e554c57e",
   "metadata": {},
   "source": [
    "The next set of plots analyzes the predicted and observed demands for individual BAs in order to shed more light on the performance of the `tell` empirical models. The first function plots the time-series and histograms of observed and predicted demands for a given BA. Using this function you can see the strong performance of `tell` in larger BAs (e.g., PJM, MISO, ERCO). They also shed some clues into the poor performance in smaller BAs. For example, the data from SEC shows bad observations that weren't caught by the data cleanining functions that are ran before the MLP models are trained. Despite its poor performance, the small loads present in SEC allow us to retain the model for that BA even though it is poor without impacting the overall fidelity of `tell`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7dc7c7-353e-4918-8561-e6074ab2b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tell.plot_mlp_ba_time_series(prediction_df, \n",
    "                             ba_to_plot = 'PJM',\n",
    "                             image_output_dir = tell_image_dir,\n",
    "                             image_resolution = 150,\n",
    "                             save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a217733-afb9-495d-887c-cbfffcc48dc6",
   "metadata": {},
   "source": [
    "Next let's take a look at the performance of the `tell` empirical models during the peak week of demand during the evaluation period. To find the peak demand week we compute a weekly rolling mean value of predicted demand using exponentially-weighted windows and then subset the data to +/- 3.5 days around the peak value. This analysis can be used to understand how well `tell` is capturing peak loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d0c20-f824-4ed0-a805-9c1b8fcf35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tell.plot_mlp_ba_peak_week(prediction_df, \n",
    "                           ba_to_plot = 'PJM',\n",
    "                           image_output_dir = tell_image_dir,\n",
    "                           image_resolution = 150,\n",
    "                           save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e511d5-c6e7-4571-b3a8-43f586755101",
   "metadata": {},
   "source": [
    "### Impact of the Supplemental Linear Model\n",
    "\n",
    "The final thing we'll explore is the impact of training a linear model on the residuals of the MLP models in `tell`. This was done because population within the BAs evolves on an annual scale as opposed to hourly like the meteorological variables and thus population is rarely selected as a strong predictor in the MLP models. Nonetheless, we know that the gradual evolution of population within a BA can impact the evolution of demand. In this final section of the notebooks we retrain the `tell` empirical models without invoking the linear model adjustment step (i.e., `mlp_linear_adjustment = False`). In most BAs the models with the linear adjustment perform slightly better than those without. This shows up most clearly in the MAPE value plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1062ff4-5204-4093-ae8b-fba70fe1c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df_nolinear, validation_df_nolinear = tell.train_batch(target_region_list = (tell.get_balancing_authority_to_model_dict().keys()),\n",
    "                                                                  mlp_linear_adjustment = False,\n",
    "                                                                  data_dir = os.path.join(tell_data_dir, r'outputs', r'compiled_historical_data'),\n",
    "                                                                  n_jobs = -1)\n",
    "\n",
    "validation_df_nolinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d708e005-0db4-4c67-852a-0f2cba651d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the R2 and MAPE score for each BA using the validation_df for the models with and without the linear adjustment step:\n",
    "impact_df = tell.plot_mlp_linear_model_impact(validation_df, \n",
    "                                              validation_df_nolinear,\n",
    "                                              image_output_dir = tell_image_dir,\n",
    "                                              image_resolution = 150,\n",
    "                                              save_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd4959-5215-49a9-ac0d-40304aea9472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.4_tell",
   "language": "python",
   "name": "py3.9.4_tell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
