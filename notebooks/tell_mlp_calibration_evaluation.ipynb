{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e343b2f-e0fd-42e8-b41a-6094f8fb6c4e",
   "metadata": {},
   "source": [
    "## Evaluation and Calibration of the Empirical Models in TELL\n",
    "\n",
    "This notebook is meant to facilitate exploring the empirical models that underpin `tell`. It will set up the meteorological variables we use and analyze different aspects of the multilayer perceptron model development and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40e24c-7a09-4399-836e-a2d68a2a522f",
   "metadata": {},
   "source": [
    "### Install the package of data underpinning `tell`\n",
    "\n",
    "`tell` is based on open-source publicly accessible data. For convienence, we've packaged all of the data underpinning this notebook into a [Zenodo data package](https://zenodo.org/record/6578641#.Yo1R7ZPMJTY). In order to run this notebook, first set the local directory where you would like to store the package data and the run the `install_quickstarter_data` function below. Note that the quickstarter data package will require ~650 MB of storage and can take several minutes to download. You will also need a dataset with sample forcing data for `tell`, also available in a [Zenodo data package](https://zenodo.org/record/6354665#.Yi-_PRDMJTY). The sample forcing data package will require ~250 MB of storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b242f29e-982a-4efb-ad1f-172145688b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start by importing the TELL package and information about your operating system:\n",
    "import os \n",
    "import tell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f8864-631b-4683-ad39-51639f1d24a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify the current working directory, the \"tell_data\" directory where the data will is stored, and the image output directory:\n",
    "current_dir =  os.path.join(os.path.dirname(os.getcwd()))\n",
    "tell_data_dir = os.path.join(current_dir, r'tell_data')\n",
    "tell_image_dir = os.path.join(tell_data_dir, r'visualizations', r'mlp_evaluation')\n",
    "\n",
    "# If the \"tell_image_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(tell_image_dir):\n",
    "   os.makedirs(tell_image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7207ea2-2e80-4cf2-8b88-800d9c27a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the TELL quickstarter data package from Zenodo:\n",
    "tell.install_quickstarter_data(data_dir = tell_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656eba23-0c08-4cfd-9b92-961a84d643f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the TELL sample forcing data package from Zenodo:\n",
    "tell.install_sample_forcing_data(data_dir = tell_data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a0c62-d668-4182-9b44-60edc9f0f606",
   "metadata": {},
   "source": [
    "### Variable Correlations\n",
    "\n",
    "The first thing we'll look at is the relationship between the predictive variables in `tell` and the historical electricity demand for different Balancing Authorities (BAs). The function below plots the correlation between the different variables in the historical observed data that underpins `tell`. In general, demand is fairly well correlated with most of the meteorological variables, with the strongest dependency being on 2-m air temperature (T2). The stength of the correlations varies significantly from BA-to-BA. Demand in some BAs is closely tied to variations in weather (e.g., NEVP, ERCO, FPL). In more moderate climates (e.g., SCL, BPAT) the relationships are weaker. This pattern is useful for interpreting the performance of the empircal models in `tell`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6ccc6-dcc5-411a-a4db-6f1924638803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the correlation between predictive variables in TELL and the historical demand in a given BA. Note that if you set the 'ba_to_plot' variable to \"All\" the function \n",
    "# will compute and plot the average correlation across all BAs:\n",
    "tell.plot_ba_variable_correlations(ba_to_plot = 'All', \n",
    "                                   data_input_dir = tell_data_dir,\n",
    "                                   image_output_dir = tell_image_dir,\n",
    "                                   image_resolution = 150,\n",
    "                                   save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10fbdbb-688f-4982-a23f-a03e6cf5f359",
   "metadata": {},
   "source": [
    "### Empirical Model Training\n",
    "\n",
    "Next we'll train the `tell` models using the standard settings found in the `mlp_settings.yml` file. By default, the `tell` multi-layer perceptron (MLP) models are trained on historical weather and load data from 2016-2018 and evaluated using data from 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c9fb4-b3f3-454f-add1-abdab4de9f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the empirical models using the standard settings:\n",
    "prediction_df, validation_df = tell.train_batch(target_region_list = (tell.get_balancing_authority_to_model_dict().keys()),\n",
    "                                                data_dir = os.path.join(tell_data_dir, r'tell_quickstarter_data', r'outputs', r'compiled_historical_data'),\n",
    "                                                n_jobs = -1)\n",
    "        \n",
    "# View the validation dataframe that contains error statistics for the trained models:\n",
    "validation_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809d300-81a1-40eb-be8a-c2958b2880b3",
   "metadata": {},
   "source": [
    "### Empirical Model Evaluation\n",
    "\n",
    "After training the models, we'll visualize their performance by plotting the error characteristics for each of the BAs in `tell`. In general, the default training settings results in models that perform quite well. 76% (41/54) of the BAs have an R2 value greater than 0.75 while 83% (45/54) have a MAPE under 10%. The following statistical values, all computed using the sklearn package, are used to evaluate the MLP models:\n",
    "\n",
    "| Parameter | Description | Documentation |\n",
    "| :-: | :- | :-: |\n",
    "| R2 | Coefficient of determination | [sklearn.metrics.r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) |\n",
    "| RMS_ABS | Root-mean-squared of the absolute error | [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) |\n",
    "| RMS_NORM| The RMS_ABS value divided by the mean | [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) |\n",
    "| MAPE| Mean absolute percentage error | [sklearn.metrics.mean_absolute_percentage_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_percentage_error.html#sklearn.metrics.mean_absolute_percentage_error) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042dc367-62c4-4e64-8210-2dac98c7edf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the statistical performance (e.g., RMS_ABS, RMS_NORM, MAPE, or R2) of the predictive models across all the BAs in TELL:\n",
    "tell.plot_mlp_summary_statistics(validation_df, \n",
    "                                 image_output_dir = tell_image_dir,\n",
    "                                 image_resolution = 150,\n",
    "                                 save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5149030-e0d7-42e7-b682-07c2faa4df86",
   "metadata": {},
   "source": [
    "It's illustrative to look at the error metrics as a function of load. To do this, we calculate the mean hourly load for each BA during the evaluation year and then plot the error statistics as a function of that mean load. Analyzing the data in this way demonstrates that the BAs with the poorly performing emprical models are almost universally the smaller BAs. The largest BAs, which are critically important for the overall demand on the grid, generally perform quite well. Of the 10 BAs with the largest mean demand, 9/10 have a MAPE value under 5% and an R2 value greater than 0.85. Conversely, of the 10 worst performing BAs (judged by their MAPE value), 7/10 have an average hourly load less than 1700 MWh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508e877-eb82-48f1-9a62-6f0637751e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the statistical performance (e.g., RMS_ABS, RMS_NORM, MAPE, or R2) of the predictive models as a function of mean load for each BA and update the validation dataframe:\n",
    "validation_df = tell.plot_mlp_errors_vs_load(prediction_df, \n",
    "                                             validation_df, \n",
    "                                             image_output_dir = tell_image_dir,\n",
    "                                             image_resolution = 150,\n",
    "                                             save_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48813f16-0333-40b8-b939-37e2e2b28526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the performance metrics for the 10 largest BAs:\n",
    "validation_df.sort_values(by='Mean_Load_MWh', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4931da1-f228-4094-99b2-6d8d11d4fe0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the performance metrics for the 10 poorest performing BAs (judged by MAPE):\n",
    "validation_df.sort_values(by='MAPE', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85275bf1-87d2-4ceb-ba68-ca27e554c57e",
   "metadata": {},
   "source": [
    "### Performance of Individual BAs\n",
    "\n",
    "The next set of plots analyzes the predicted and observed demands for individual BAs in order to shed more light on the performance of the `tell` empirical models. The first function plots the time-series and histograms of observed and predicted demands for a given BA. Using this function you can see the strong performance of `tell` in larger BAs (e.g., PJM, MISO, ERCO). They also shed some clues into the poor performance in smaller BAs. For example, the data from SEC shows bad observations that weren't caught by the data cleanining functions that are ran before the MLP models are trained. Despite its poor performance, the small loads present in SEC allow us to retain the model for that BA even though it is poor without impacting the overall fidelity of `tell`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7dc7c7-353e-4918-8561-e6074ab2b43a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the performance characteristics of a single BA:\n",
    "tell.plot_mlp_ba_time_series(prediction_df, \n",
    "                             ba_to_plot = 'PJM',\n",
    "                             image_output_dir = tell_image_dir,\n",
    "                             image_resolution = 150,\n",
    "                             save_images = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a217733-afb9-495d-887c-cbfffcc48dc6",
   "metadata": {},
   "source": [
    "Next let's take a look at the performance of the `tell` empirical models during the peak week of demand during the evaluation period. To find the peak demand week we compute a weekly rolling mean value of predicted demand using exponentially-weighted windows and then subset the data to +/- 3.5 days around the peak value. This analysis can be used to understand how well `tell` is capturing peak loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d0c20-f824-4ed0-a805-9c1b8fcf35ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the performance of the models for a given BA during it's peak demand week during the evaluation year (2019):\n",
    "tell.plot_mlp_ba_peak_week(prediction_df, \n",
    "                           ba_to_plot = 'NEVP',\n",
    "                           image_output_dir = tell_image_dir,\n",
    "                           image_resolution = 150,\n",
    "                           save_images = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941338e-3eb2-4b5a-8bcc-323dabaf90c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
